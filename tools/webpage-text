#!/usr/bin/env python3
import argparse
import sys
import requests
from bs4 import BeautifulSoup
import textwrap

def extract_text(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
            
        # Get text and clean it up
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        return text
    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description='Extract text content from a webpage')
    parser.add_argument('url', help='URL to extract text from')
    parser.add_argument('-n', type=int, default=100, help='Number of lines to display (default: 100)')
    args = parser.parse_args()

    text = extract_text(args.url)
    lines = text.split('\n')
    
    # Only show the specified number of lines
    for line in lines[:args.n]:
        if line.strip():  # Only print non-empty lines
            print(line)

if __name__ == '__main__':
    main()